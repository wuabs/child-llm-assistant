{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/wuabs/child-llm-assistant/blob/main/training/colab_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_GgdqJocfqh"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets peft accelerate bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vO2CV2N-ckqx"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuV64wLpcmu0"
   },
   "outputs": [],
   "source": [
    "model_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4egU6NITcoHH"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name, load_in_8bit=True, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6rRZxRVuvqC5"
   },
   "outputs": [],
   "source": [
    "# LoRA config\n",
    "with open(\"lora_config.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    config_dict = json.load(f)\n",
    "lora_config = LoraConfig(**config_dict)\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CkE9KBdwcp3o"
   },
   "outputs": [],
   "source": [
    "# Датасет\n",
    "raw_dataset = load_dataset(\"text\", data_files=\"data/lm_dataset.txt\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_dataset = raw_dataset.map(tokenize_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cWIJ-TFJcqUL"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Аргументы\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/lora-lm\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=20,\n",
    "    save_steps=200,\n",
    "    fp16=True,\n",
    "    save_total_limit=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZWTtoFuEcvVt"
   },
   "outputs": [],
   "source": [
    "# Обучение\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    data_collator=data_collator\n",
    ")\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqapaA5jwB1E"
   },
   "outputs": [],
   "source": [
    "# Сохраняем модель\n",
    "model.save_pretrained(\"./models/lora-lm\")\n",
    "tokenizer.save_pretrained(\"./models/lora-lm\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMdjKvtnrN1YO2t9cL9LKSH",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
